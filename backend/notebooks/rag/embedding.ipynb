{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76ab9a4d-e967-4cc5-a416-64d00f22bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas.io.formats.style\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import chromadb\n",
    "import tiktoken\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import torch.nn.functional as F\n",
    "import sqlite3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f0b16-c7d3-46b7-987f-76311c50d476",
   "metadata": {},
   "source": [
    "### 1. Testing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d897d4-c962-495e-a83a-8db16d3f9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Large language models are transforming natural language processing.\"\n",
    "\n",
    "models = {\n",
    "    \"OpenAI ada-002\": {\n",
    "        \"type\": \"openai\",\n",
    "        \"model\": \"text-embedding-ada-002\"\n",
    "    },\n",
    "    \"MiniLM\": {\n",
    "        \"type\": \"sbert\",\n",
    "        \"model\": \"all-MiniLM-L6-v2\"\n",
    "    },\n",
    "    \"BGE Base\": {\n",
    "        \"type\": \"sbert\",\n",
    "        \"model\": \"BAAI/bge-base-en-v1.5\"\n",
    "    },\n",
    "    # \"E5 Base\": {\n",
    "    #     \"type\": \"sbert\",\n",
    "    #     \"model\": \"intfloat/e5-base\"\n",
    "    # },\n",
    "    # \"E5 Large\": {\n",
    "    #     \"type\": \"sbert\",\n",
    "    #     \"model\": \"intfloat/e5-large\"\n",
    "    # },\n",
    "    \"Snowflake\": {\n",
    "        \"type\": \"sbert\",\n",
    "        \"model\": \"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
    "    },\n",
    "    # \"Jina\": {\n",
    "    #     \"type\": \"other\",\n",
    "    #     \"model\": \"jinaai/jina-embeddings-v3\"\n",
    "    # },\n",
    "    # \"Solon\": {\n",
    "    #     \"type\": \"solon\",\n",
    "    # }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5f6381-2623-48cd-b2b6-704b2a6d9bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jinaai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jinaai\u001b[38;5;241m/\u001b[39mjina\u001b[38;5;241m-\u001b[39membeddings\u001b[38;5;241m-\u001b[39mv3\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jinaai' is not defined"
     ]
    }
   ],
   "source": [
    "jinaai/jina-embeddings-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c961e6f6-4343-4559-9ad5-ec72c62b8972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a130db6f-dd8f-47e6-8097-1660cacd6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73c092c-a8ed-4b63-90da-47789291dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPEN_AI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c7d0c-506d-4398-87f9-c970e9219f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e49625-02c3-43db-9495-8b1e52aff2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testowanie modelu: OpenAI ada-002\n",
      "üîç Testowanie modelu: MiniLM\n",
      "üîç Testowanie modelu: BGE Base\n",
      "üîç Testowanie modelu: Snowflake\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_308a5_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 3.2%, transparent 3.2%);\n",
       "}\n",
       "#T_308a5_row1_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 16.0%, transparent 16.0%);\n",
       "}\n",
       "#T_308a5_row2_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 39.5%, transparent 39.5%);\n",
       "}\n",
       "#T_308a5_row3_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #5fba7d 100.0%, transparent 100.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_308a5\">\n",
       "  <caption>‚è±Ô∏è Por√≥wnanie embedding√≥w</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_308a5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_308a5_level0_col1\" class=\"col_heading level0 col1\" >Dimension</th>\n",
       "      <th id=\"T_308a5_level0_col2\" class=\"col_heading level0 col2\" >Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_308a5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_308a5_row0_col0\" class=\"data row0 col0\" >MiniLM</td>\n",
       "      <td id=\"T_308a5_row0_col1\" class=\"data row0 col1\" >384</td>\n",
       "      <td id=\"T_308a5_row0_col2\" class=\"data row0 col2\" >0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_308a5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_308a5_row1_col0\" class=\"data row1 col0\" >BGE Base</td>\n",
       "      <td id=\"T_308a5_row1_col1\" class=\"data row1 col1\" >768</td>\n",
       "      <td id=\"T_308a5_row1_col2\" class=\"data row1 col2\" >0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_308a5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_308a5_row2_col0\" class=\"data row2 col0\" >Snowflake</td>\n",
       "      <td id=\"T_308a5_row2_col1\" class=\"data row2 col1\" >1024</td>\n",
       "      <td id=\"T_308a5_row2_col2\" class=\"data row2 col2\" >0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_308a5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_308a5_row3_col0\" class=\"data row3 col0\" >OpenAI ada-002</td>\n",
       "      <td id=\"T_308a5_row3_col1\" class=\"data row3 col1\" >1536</td>\n",
       "      <td id=\"T_308a5_row3_col2\" class=\"data row3 col2\" >0.620400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e39a9bc5d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_models = {}\n",
    "for name, config in models.items():\n",
    "    if config[\"type\"] == \"sbert\":\n",
    "        sbert_models[name] = SentenceTransformer(config[\"model\"])\n",
    "\n",
    "results = []\n",
    "for name, config in models.items():\n",
    "    print(f\"üîç Testowanie modelu: {name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if config[\"type\"] == \"openai\":\n",
    "        response = openai.embeddings.create(\n",
    "            input=[text],\n",
    "            model=config[\"model\"]\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "    elif config[\"type\"] == \"sbert\":\n",
    "        model = sbert_models[name]\n",
    "        if \"e5\" in config[\"model\"]:\n",
    "            text_to_encode = f\"query: {text}\"\n",
    "        else:\n",
    "            text_to_encode = text\n",
    "        embedding = model.encode(text_to_encode, convert_to_numpy=True)\n",
    "    elif config[\"type\"] == \"other\":\n",
    "        model = SentenceTransformer(\"jinaai/jina-embeddings-v3\", trust_remote_code=True)\n",
    "        embedding = model.encode(text_to_encode, convert_to_numpy=True)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"OrdalieTech/Solon-embeddings-large-0.1\")\n",
    "        model = AutoModel.from_pretrained(\"OrdalieTech/Solon-embeddings-large-0.1\")\n",
    "        embedding = model.encode(text_to_encode, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    dim = len(embedding)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Dimension\": dim,\n",
    "        \"Time (s)\": round(elapsed, 4)\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.sort_values(\"Time (s)\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.style.bar(subset=[\"Time (s)\"], color=\"#5fba7d\").set_caption(\"‚è±Ô∏è Por√≥wnanie embedding√≥w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502118bf-8f36-4788-be0d-fe94d84be212",
   "metadata": {},
   "source": [
    "### 2. Creating Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b78fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7302016-ad89-4fab-8621-31edc6c24568",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CHROMA = \"../../chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec659cf2-59e5-4fc5-a611-f0644b5ea1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=PATH_CHROMA)\n",
    "collection = client.get_or_create_collection(name=\"interview_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2940430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection.get()[\"ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8c6c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(name=\"interview_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36cb2441-403d-4965-ad65-2cd3742685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"Snowflake/snowflake-arctic-embed-l-v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89cd0954-0fa5-4ccc-943c-18b733a40de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cec1e4-8c2d-44e1-8c02-9c23463df446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     0, 151477,   8484,      2]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model)\n",
    "tokens = tokenizer(\"Tw√≥j tekst\", return_tensors=\"pt\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034cc88-9732-4e58-ad40-38e82b007587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e952cd-f63d-482c-aa98-bf4c6b4049b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://skphd.medium.com/large-language-model-llm-interview-questions-ded6264547f1\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12ca158-3d0f-4429-a270-6f7526c86946",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "pattern = re.compile(r\"^\\d+\\.\\s?.+\")\n",
    "\n",
    "questions = []\n",
    "for strong in soup.find_all(\"strong\"):\n",
    "    text = strong.get_text(strip=True)\n",
    "    if pattern.match(text):\n",
    "        questions.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092a8cbc-53ca-4d60-8369-7d5d6aad3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_python = \"https://www.datainterview.com/blog/top-100-python-interview-questions\"\n",
    "response_python = requests.get(url_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129cedbd-d340-4bec-8262-f1f8769685f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Do you need a vector store for all text-based LLM use cases?\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "290a4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [ re.sub(r'^\\d+\\.\\s*', '', question) for question in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fef84b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you need a vector store for all text-based LLM use cases?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f2645f-d6d8-4b64-9ca4-cf76d1e89dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions(h3_class):\n",
    "    h3 = soup.find('h3', class_=h3_class)\n",
    "    print(h3)\n",
    "    if h3:\n",
    "        next_ol = h3.find_next_sibling(['ol', 'ul'])  # szukamy tylko list\n",
    "        if next_ol:\n",
    "            return [li.get_text(strip=True) for li in next_ol.find_all('li')]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f49027e-ad2c-4343-822d-cea188492ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "basic_questions = extract_questions('basic-python-interview-questions')\n",
    "intermediate_questions = extract_questions('intermediate-python-interview-questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "006e05e5-71ef-4f1c-8e06-f3189c9ab954",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_questions = [\n",
    "    \"How do you remove duplicates from a list while maintaining order?\",\n",
    "    \"What is the purpose of the enumerate() function, and how do you use it?\",\n",
    "    \"Explain how list slicing works, including the use of negative indices.\",\n",
    "    \"How do you flatten a nested list in Python?\",\n",
    "    \"What is the difference between append() and extend() in lists?\",\n",
    "    \"How do you use the zip() function in Python?\",\n",
    "    \"How do you find the frequency of elements in a list?\",\n",
    "    \"What are Python comprehensions, and how do they improve code readability?\",\n",
    "    \"Explain the difference between isinstance() and type checking with type().\",\n",
    "    \"How do you merge multiple dictionaries in Python 3.9+?\",\n",
    "    \"What are Python closures, and how do they work?\",\n",
    "    \"How do you reverse the order of words in a string?\",\n",
    "    \"What is the purpose of collections.defaultdict()?\",\n",
    "    \"How do you check if all elements in a list are unique?\",\n",
    "    \"What is the purpose of collections.OrderedDict()?\",\n",
    "    \"Explain how to create a recursive function in Python.\",\n",
    "    \"What are lambda functions, and when are they most useful?\",\n",
    "    \"How do you create a simple iterator class in Python?\",\n",
    "    \"What is the itertools.product() function, and where is it useful?\",\n",
    "    \"How do you handle large files in Python without loading the entire file into memory?\",\n",
    "    \"How do you implement a binary search algorithm in Python?\",\n",
    "    \"Explain the concept and use of decorators in Python.\",\n",
    "    \"How do you implement a custom sorting function using sorted() with a lambda?\",\n",
    "    \"What is the functools.reduce() function, and how does it work?\",\n",
    "    \"How do you implement memoization in Python?\",\n",
    "    \"How do you use the collections.Counter() for counting elements in an iterable?\",\n",
    "    \"Implement a function that generates all permutations of a given string.\",\n",
    "    \"What is the use of heapq, and how do you create a min-heap?\",\n",
    "    \"Explain the with statement and how it manages resources.\",\n",
    "    \"How do you implement a queue using Python's deque?\",\n",
    "    \"What is multithreading, and how does Python handle it with the GIL?\",\n",
    "    \"Explain how to build a context manager using contextlib.\",\n",
    "    \"How do you work with JSON data in Python?\",\n",
    "    \"Write a function that merges overlapping intervals in a list of tuples.\",\n",
    "    \"How do you parallelize code execution using Python's multiprocessing module?\",\n",
    "    \"How do you handle CSV data with large file sizes using Pandas efficiently?\",\n",
    "    \"Explain the concept of method chaining in Python.\",\n",
    "    \"How do you use the pathlib module for file system operations?\",\n",
    "    \"What is asyncio, and how do you use it for asynchronous programming?\",\n",
    "    \"How do you use pandas.groupby() to perform complex data aggregation?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4281d854-8879-4732-8085-b9c48d8dc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledAnswer(BaseModel):\n",
    "    explanation: str\n",
    "\n",
    "class Answers(BaseModel):\n",
    "    answers: List[LabeledAnswer]\n",
    "    question: str\n",
    "    difficulty: str\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Answers)\n",
    "\n",
    "format_instructions = parser.get_format_instructions().replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions with explanations and difficulty ratings.\"),\n",
    "    (\"human\", f\"\"\"Please answer the following question by generating **10 different correct answers**. 3 of them should be in 1-2 sentences, 4 of them should be in 3-4, the other 3 should be in 4-5 sentences.\n",
    "For each answer, provide:\n",
    "- explanation\n",
    "for question provide:\n",
    "- difficulty level (Easy, Medium, Hard, Very Hard)\n",
    "- repeat question i provided to you to field 'question'\n",
    "\n",
    "Return the result strictly in this JSON format:\n",
    "{format_instructions}\n",
    "\n",
    "Question: {{question}}\"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbe2a3c2-668d-409c-b314-2d755180a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1, api_key=OPEN_AI_API_KEY) \n",
    "\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "590444cf-2754-4dae-b155-0371e795c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\n",
    "    \"question\": \"What is overfitting in machine learning?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f9a454b-8457-4d28-9006-c7fc2ab8d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you need a vector store for all text-based LLM use cases?\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c54d8d55-cbeb-4412-9fb0-548905f71c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01234567891011121314151617181920212223242526272829303132333435363738394041424344454647"
     ]
    }
   ],
   "source": [
    "answers_list = []\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    result = chain.invoke({\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    answers_list.append(result)\n",
    "\n",
    "    print(i, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a6c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f7aef22-79c4-4b35-9651-ee0bfcfb5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is catastrophic forgetting in fine-tuning LLMs?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_list[4].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "348838b1-ba37-40e9-a68b-6c65d541bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDatas(BaseModel):\n",
    "    difficulty: str\n",
    "    type_question: str\n",
    "    question: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1238d-2a7d-45ca-959a-912e13ace0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    collection.add(\n",
    "        ids=[doc_id],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[{\"source\": \"stackoverflow\", \"question\": doc[\"question\"], \"url\": doc[\"url\"], \"version\": doc[\"version\"]}],\n",
    "        documents=[chunk]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "877363cc-27e0-4a54-b7c8-0cb02ff90a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_chromadb(ID, type_question, answers_list):\n",
    "    en_id = 0\n",
    "\n",
    "    for answer_list in answers_list:\n",
    "        difficulty = answer_list.difficulty\n",
    "        question = answer_list.question\n",
    "        metadatas = MetaDatas(difficulty=difficulty, type_question=type_question, question=question)\n",
    "        \n",
    "        for idx, answer in enumerate(answer_list.answers):\n",
    "            explanation = answer.explanation\n",
    "            exp_id = f\"{ID}{en_id}_{idx}\"        \n",
    "            embedding = sentence_model.encode(explanation, convert_to_numpy=True)\n",
    "            \n",
    "            \n",
    "            collection.add(\n",
    "                ids=[exp_id],\n",
    "                embeddings=[embedding],\n",
    "                metadatas=[{\"difficulty\": metadatas.difficulty, \"type_question\": metadatas.type_question, \"question\": metadatas.question}],\n",
    "                documents=[explanation]\n",
    "            )\n",
    "\n",
    "        en_id += 1\n",
    "        print(en_id, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34c7ded5-2120-4767-a97f-0ae40d10426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456789101112131415161718192021222324252627282930313233343536373839404142434445464748"
     ]
    }
   ],
   "source": [
    "add_to_chromadb(\"LLM_QUESTION_\", \"llm\", answers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b40624c7-64d6-47f5-b625-515c56390fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789101112131415161718192021222324252627282930313233343536373839"
     ]
    }
   ],
   "source": [
    "answers_python_list = []\n",
    "\n",
    "for i, question in enumerate(python_questions):\n",
    "    result = chain.invoke({\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    answers_python_list.append(result)\n",
    "\n",
    "    print(i, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f32a7e01-033a-4f1a-87aa-bfa4bf0276b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345678910111213141516171819202122232425262728293031323334353637383940"
     ]
    }
   ],
   "source": [
    "add_to_chromadb(\"PYTHON_QUESTION_\", \"python\", answers_python_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c375848-703b-4c2b-9bf6-159716bdd8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you remove duplicates from a list while maintaining order?\n"
     ]
    }
   ],
   "source": [
    "print(answers_python_list[0].question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46614399-7c04-4eac-b0f4-39f1a096ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"append is a method used to add elements to the list in python. It adds element on the end of the list\"\n",
    "query_wrong = \"append is a method which adds element at the front of the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddd98e0c-216b-463b-8c23-6a29a8e88601",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[sentence_model.encode(query, convert_to_numpy=True)],\n",
    "    n_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1eb7a3a-eed3-485c-b020-8301dd67e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['append() is a method that adds its argument as a single element at the end of a list, which can be any Python object. On the other hand, extend() takes an iterable and appends each of its elements to the list individually. This means using append() with a list will result in a nested list, while extend() will merge the elements of the iterable into the original list.', 'The append() method adds a single element to the end of the list, while extend() adds all elements of an iterable to the list.', 'append() and extend() are both list methods that modify the list in place, but they do so in different ways. append() is used to add a single object to the end of the list. For example, appending a list to another list will result in a list of lists. extend(), however, is designed to take an iterable and add each of its elements to the list, effectively merging the iterable into the list. This makes extend() more suitable for concatenating lists or adding multiple values at once, as it adds each element of the iterable separately to the list.']\n"
     ]
    }
   ],
   "source": [
    "print(results[\"documents\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "432e82f3-d2c8-4895-99bc-ba5ec1a1f51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3567889630794525, 0.4606739282608032, 0.47948014736175537]]\n"
     ]
    }
   ],
   "source": [
    "print(results[\"distances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59450842-5f1c-4907-bdd2-dc0afdbf8e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokument 1: Similarity = 0.8056, Similarity wrong = 0.5263\n",
      "Dokument 2: Similarity = 0.7362, Similarity wrong = 0.5644\n",
      "Dokument 3: Similarity = 0.7382, Similarity wrong = 0.5265\n"
     ]
    }
   ],
   "source": [
    "query = \"append is a method used to add elements to the list in python.\"\n",
    "query_wrong = \"append which is used to print elements to the console\"\n",
    "\n",
    "query_emb = sentence_model.encode(query, convert_to_tensor=True)\n",
    "query_wrong_emb = sentence_model.encode(query_wrong, convert_to_tensor=True)\n",
    "doc_embs = sentence_model.encode(results[\"documents\"][0], convert_to_tensor=True)\n",
    "\n",
    "similarities = util.cos_sim(query_emb, doc_embs)\n",
    "similarities_wrong = util.cos_sim(query_wrong_emb, doc_embs)\n",
    "\n",
    "for i, (score, score_wrong) in enumerate(zip(similarities[0], similarities_wrong[0])):\n",
    "    print(f\"Dokument {i+1}: Similarity = {score.item():.4f}, Similarity wrong = {score_wrong.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d4e64d2-5df0-4d7c-a6ce-dd217cf53ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DB = \"../../documents.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "852aba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(PATH_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS documents;\") \n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "badd7454-72d3-46fe-9758-7caac5afcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(PATH_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS documents (\n",
    "    question TEXT PRIMARY KEY,\n",
    "    type_question TEXT,\n",
    "    difficulty TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c695374-5ac7-4af9-ad48-d4298a3c40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_document(doc_id, question, type_question, difficulty):\n",
    "    conn = sqlite3.connect(PATH_DB)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT OR REPLACE INTO documents (question, type_question, difficulty)\n",
    "        VALUES (?, ?, ?)\n",
    "    \"\"\", (question, type_question, difficulty))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9c2931c-d135-4a07-99cd-1a2a3faf4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = collection.get()\n",
    "\n",
    "for doc_id, metadata in zip(all_docs[\"ids\"], all_docs[\"metadatas\"]):\n",
    "    question = metadata.get(\"question\", \"\")\n",
    "    type_question = metadata.get(\"type_question\", \"\")\n",
    "    difficulty = metadata.get(\"difficulty\", \"\")\n",
    "    \n",
    "    insert_document(doc_id, question, type_question, difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0dc1238b-1075-4269-8031-9556f217bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_by_question(search_term):\n",
    "    conn = sqlite3.connect(PATH_DB)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT * FROM documents WHERE question LIKE ?\n",
    "    \"\"\", (f\"%{search_term}%\",))\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0325c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_by_question(\"How do you remove duplicates from a list while maintaining order?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb93b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c684a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dbcf492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(PATH_DB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "SELECT * FROM documents\n",
    "\"\"\")\n",
    "\n",
    "results = cursor.fetchall()\n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "826d63c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7718a531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How does Adaptive Softmax speed up large language models?', 'llm', 'Hard')\n"
     ]
    }
   ],
   "source": [
    "print(results[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_better",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
